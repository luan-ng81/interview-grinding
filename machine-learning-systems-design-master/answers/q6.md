# Answer to question 6

**Question 6**

Build a system that return images associated with a query like in Google Images.

pipeline: 
- majority: translate to text, find page contain images and keyword query.
	- enhanced search for legal reason, fairness, etc 


pipeline: text -> enhanced text -> search hubs for relevants results -> use models to compute similarity score of relevant results -> optional: post processing -> results 

- rare instances; search similar images 

tokenizer -> convert to standard embedding (word2vec) (vector representation of the text) -> Model -> latent reprsentation(last layer) -> output 



**Answer**
Question: 
input: 
- Clarify whether input is image or text => Assume text 
 
output: image

Procedure: 
1. Enhancing text: 
- More it more clear: topic modelling (queen -> person, chess, band), next word prediction (search query: funny -> ), Synonyms and related terms 
- Make it more concise: Named Entity Recognition, Intent Classification (topic modelling)
- Make it more fair (satisfy constraints): next word prediction(tell m couple ) -> maybe optional because postprocessing is better. 

2. search hubs for relevants results: 
- data mining techniques to clean and filter relevant results 
- output: relevance images  

3. Use model to score list of relevance items (learning to rank step): 

- Goal: given query, computing relevance score (i.e similarity score) between query and list of relevance images froms step 2

  + Extract query embedding and image embedding, feed into CLIP to extract similarity score for each pair. 

  + Rank them
    * Simply sort all the relevance score


###################################################### 
tradition: 
step 1: input -> ML model -> output (score) | step2:  score -> optimization model (LP, QP) -> rank items ( [1, 3, 5, 2, 4])

loss: accuracy + penalty of constraints ( if you only use loss to enforce constraint, this will not guranteee constraint satisfaction)

argmax_Pi  score* Pi * constant_b (utility score)
subject to: 1) (Pi*constraint_b) = exposure_score of each indiviual/group  >= threshold (gurobi, ortools )


[1 0 0 0 0 
 0 0 1 0 0 ]

 Pi has dimension n x n (where n is # of items to rank)

 ######################################################
 new apporach:
 	 input -> ML model -> output (score) -> optimization model (LP, QP) -> objective -> rank 

 training objective: objective (decision loss) or regret: penalize the different between grouth true objective and predicted objective 


 challenge: for gradient based training, you need gradients of optimization model (LP or QP)
 - formulate the objective to fit the business needs 



 4. Post processing: 
 - Sort with constraints (fairness constraints: e.g make sure the top 10 contains candidates from different categories, which require meta data of each item itself) 
 - Note: if the model is already trained with constrained satisfaction guarantee, then no need for postprocessing


 